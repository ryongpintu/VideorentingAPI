in every part of application you going to think query that you are executing ahead of time
and design your database based on that query.
that is general principle of design the db

approch 1

type:mongoose.Schema.Types.ObjectId,
ref:'Author'

populate Method

populate('author','name -_id') := mongoose will query the Author Schema or collction and populate the document
populate('category','name')

mongo doesnot care about the invalid id 
it is not consistent
like the traditional db

in mongo there is no relationship with data integrity in db
you can change the id in the db and mongo will be absolutely fine with it


approach 2

embedded document

Course.model('course', new mongoose.Schema(

name:String,
author:authorSchema // here we are embiding the documet inside the course document

))

createCourse('node', new Author({name:"Ramesh"}))
all this sub-documents have same property like the general document
like we can impliment the validation like author.name is required
however this sub-documet does not save by its own. It can only be save in context of his parents

like course.author.name ='Hello'
course.save() // we donot have course.author.save() its wrong

update({query object},$set:{},$unset:{})


while creating the endpoints for the Rental 
/api/rentals

create the rental Schema 
and embedded the customer document and movie documet 
like this

const Rental = mongoose.model('rental',new mongoose.Shema({
	customer:{
	type: new mongoose.Schema({  // Here we donot include the customer Schema type because do not need all the
									20 properties
	name:String,
	phone:String,
	isGold:Boolean
	})
	},
	movie:{
	type:new mongoose.Schema({
	title:String,
	dailyRentalRate:Number
	})
	}
}))


Transaction in sql
 in mongo two phase commit
 or lib fawn
 const Fawn = require('fawn')

try{
	new Fawn.task()
 	.save('rentals',rental)
 	.update('movies',{_id:_id},{
 	$inc:{stock:-1}
 	})
 	.run()
 	}catch(){

 	}
 
 the collection that is generated by the fawn lib 

 fawn uses that collection to perform the two phase commits

 when you run fawn , it add new documet in collection which represents transaction and then execute each of the operation independently 
 after the succesfull collection it delete this documet 


 mongoose is abstraction over mongodb driver 
 so when you create new document or object mongoose talks to the driver to generate id

 _id: 24 characters
 12bytes
 4bytes // timestamp
 3bytes // machine identifier
 2bytes // process identifier
 3bytes for counter

 2*8 256
 2^24 16M

 this object id is almost unique but not hundred percent

 mongoose.Types.ObjectId.isValid('23323');

 id.getTimeStamp();


 validating the objectid using the Joi-objectid package

 customerId:Joi.objctId().required();


 note:- findById(id) or findOne({email:req.body.email})


 lodash modify the res.send
 modified version of underscore
user = new User(_.pick(req.body,['name','email','password'])) // it possible that melicious user may try to 
send data and save data in db so here it can be filtered
 user =_.pick(user,['name','email'])
 res.send(user);

 joi password complexity

 registering user
 const salt = bcrypt.genSalt(10);
 bcrypt.hash(req.body.password,salt);

Authenticating user 
user= User.findOne({email:req.body.email})
bcrypt.compare(req.body.password,user.password);

jsonwebtoken
config
jwt.sign({_id:id},config.get('jwtPrivateKey'));


//information expert principle

how to add the method in schema

userSchema.methods.generateAuthToken=function(){
	return jwt.sign({_id:this._id},config.get('jwtPrivateKey')); 


}
// cannot use arrow here since it not have this keyword
//and it only used in stand alone functiion


authrization middleware

module.exports =(req,res,next)=>{
	
	const token = req.header('x-auth-token');
	(!token) return res.status(401).send('access denied no token provided !');
	try{
	const decode=jwt.verify(token,config.get('jwtPrivateKey'));
	req.user=decode // set to req so that we can use it later in routes like req.user._id
	next()
	}
	catch(ex){
	 return res.status(400).send('access denied invalid token !');
	
	}
	
}

// we could add this middleware in index.js that will be executed before
every routes but we dont want this because in this app we don't need to protect
all the routes some of them are public like getting the list reading the movie
so we need to add it in the particular routes
like this
router.post('/',auth,(req,res)={
	
});


getting the current user



net stop mongodb
net start mongodb

register error middleware after all the middleware 

express-async-errors  // not error

winston is popular logger package
custom logger
default logger

winston.log('error',err.message); //err is error object
or use halper class

winston.error(err.message,err) // it loggs the error message and meta data to log file
like message stack level timestamp 
winston.add(winston.transports.File,{filename:'logfile'});

winston has various transport like
file
console
http

logg message to mongodb
npm i winston-mongodb3.0.0
just require('winston-mongodb')
winston.add(winston.transports.MongoDB,{db:'mongodb://localhost/vidlydb',
level:error}); // you can log data in other db

this winston only catches error that happens to be a part of request processing pipelines. that is only to the express.
if outside context of express it not gonna catch
like
put throw error in the index.js

so how to catch these unhandled error

process.on('uncaughtException',(ex)=>{
	console.log('we caught error');
	winston.error(ex.message,ex); // this will add in log ex is metadata
});

so how to catch these unhandled promises

process.on('unhandledRejection',(ex)=>{
	console.log('we caught error');
	winston.error(ex.message,ex); // this will add in log ex is metadata
});

but there is better way

with winston happer class handleExceptions

winston.handleExceptions(new winston.transports.File,{filename:'uncaughtException.log'})

process.on('unhandledRejection',(ex)=>{
	throw ex;
});

you should exit the process because the process in unclean state in production use process manager which automatically starts process

